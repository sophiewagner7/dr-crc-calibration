{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR CRC Calibration\n",
    "\n",
    "Author: Sophie Wagner, sw3767@cumc.columbia.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "import numpy as np  # For matrix manipulation\n",
    "import pandas as pd  # For output/input data processing\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "from csaps import csaps\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Load .py files\n",
    "import common_functions as func\n",
    "import calibration_plots as p\n",
    "import configs as c\n",
    "import gof\n",
    "\n",
    "\n",
    "# Some aesthetic options\n",
    "np.set_printoptions(suppress=True, linewidth=300, formatter={'float': '{: 0.9f}'.format})\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix setup, normalization, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_normalize(matrix):\n",
    "    for age_layer in range(matrix.shape[0]):  # Loop over each age layer\n",
    "        layer = matrix[age_layer]\n",
    "        # Calculate the sum of non-diagonal elements for each row\n",
    "        sum_of_columns = np.sum(layer, axis=1) - np.diag(layer)\n",
    "        # Set the diagonal elements\n",
    "        np.fill_diagonal(layer, 1 - sum_of_columns)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def create_matrix():\n",
    "    matrix = np.zeros((len(c.age_layers), len(c.health_states), len(c.health_states)))\n",
    "    matrix[:, 0, 1] = func.probtoprob(0.005)  # Healthy to LR\n",
    "    matrix[:, 1, 2] = func.probtoprob(0.015)  # LR to HR\n",
    "    matrix[:, 2, 3] = func.probtoprob(0.05)  # HR to uLoc\n",
    "    matrix[:, 3, 4] = func.probtoprob(0.45)  # uLoc to uReg\n",
    "    matrix[:, 4, 5] = func.probtoprob(0.50)  # uReg to uDis\n",
    "    matrix[:, 3, 6] = func.probtoprob(0.20)  # uLoc to dLoc\n",
    "    matrix[:, 4, 7] = func.probtoprob(0.60)  # uReg to dReg\n",
    "    matrix[:, 5, 8] = func.probtoprob(0.90)  # uDis to dDis\n",
    "\n",
    "    matrix = add_acm(matrix)  # ACM\n",
    "    matrix = add_csd(matrix)  # CSD\n",
    "    matrix = constrain_matrix(matrix)  # constrain\n",
    "    matrix = row_normalize(matrix)  # normalize\n",
    "\n",
    "    return matrix\n",
    "hlr = func.probtoprob(0.01)\n",
    "locreg=func.probtoprob(0.5)\n",
    "def constrain_matrix(matrix):\n",
    "\n",
    "    # Progression Block\n",
    "    matrix[:, 0, 1] = matrix[:, 0, 1].clip(0.0000001, hlr)\n",
    "    matrix[:, 1, 2] = np.maximum(matrix[:, 0, 1], matrix[:, 1, 2])  \n",
    "    matrix[:, 2, 3] = np.maximum(matrix[:, 1, 2], matrix[:, 2, 3])\n",
    "    matrix[:, 3, 4] = np.maximum(locreg, matrix[:, 3, 4])\n",
    "    matrix[:, 3, 4] = np.maximum(matrix[:, 2, 3], matrix[:, 3, 4])\n",
    "    matrix[:, 4, 5] = np.maximum(matrix[:, 3, 4], matrix[:, 4, 5])\n",
    "\n",
    "    # Detection Block\n",
    "    matrix[:, 3, 6] = np.maximum(0.000001, matrix[:, 3, 6])\n",
    "    matrix[:, 4, 7] = np.maximum(matrix[:, 3, 6], matrix[:, 4, 7])\n",
    "    matrix[:, 5, 8] = np.maximum(matrix[:, 4, 7], matrix[:, 5, 8])\n",
    "    \n",
    "    # Age dependencies\n",
    "    matrix[:, 0, 1] = np.maximum.accumulate(matrix[:,0,1])\n",
    "    # matrix[:, 1, 2] = np.maximum.accumulate(matrix[:,0,1])\n",
    "    # matrix[:, 2, 3] = np.maximum.accumulate(matrix[:,0,1])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_acm(matrix):\n",
    "    matrix[:, 0, 10] = c.acm_rate  # Healthy to ACM\n",
    "    matrix[:, 1:3, 12] = c.acm_rate[:, np.newaxis]  # Polyp to ACM\n",
    "    matrix[:, 3:6, 13] = c.acm_rate[:, np.newaxis]  # Undiagnosed to ACM\n",
    "    matrix[:, 6:9, 11] = c.acm_rate[:, np.newaxis]  # Cancer to ACM\n",
    "    matrix[:, 9, 9] = 1  # Stay in CSD\n",
    "    matrix[:, 10, 10] = 1  # Stay in ACM\n",
    "    matrix[:, 11, 11] = 1  # Stay in Cancer ACM\n",
    "    matrix[:, 12, 12] = 1  # Stay in Polyp ACM\n",
    "    matrix[:, 13, 13] = 1  # Stay in uCRC ACM\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_csd(matrix):\n",
    "    matrix[:, 6, 9] = c.csd_rate[:, 0]\n",
    "    matrix[:, 7, 9] = c.csd_rate[:, 1]\n",
    "    matrix[:, 8, 9] = c.csd_rate[:, 2]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_markov(matrix, starting_age=20, max_age=100):\n",
    "    \n",
    "    current_age = starting_age\n",
    "    stage, age_layer = 1, 0\n",
    "    month_pop, pop_log = c.starting_pop, c.starting_pop\n",
    "    inc_log = np.zeros(pop_log.shape)  # to track new incidences in each state\n",
    "    matrixT = matrix.transpose(0,2,1)\n",
    "    inflow_matrix = np.tril(matrixT, k=-1)\n",
    "    \n",
    "    while current_age <= max_age:\n",
    "        \n",
    "        # Matrix multiplication (state transition)\n",
    "        mat, inflow_mat = matrixT[age_layer], inflow_matrix[age_layer] \n",
    "        month_inc = np.matmul(inflow_mat, month_pop)  # (9, 9)(9, 1)->(9, 1)\n",
    "        month_pop = np.matmul(mat, month_pop)  # (9, 9)(9, 1)->(9, 1)\n",
    "        \n",
    "        # Add to log\n",
    "        inc_log = np.concatenate((inc_log, month_inc), axis=1)\n",
    "        pop_log = np.concatenate((pop_log, month_pop), axis=1)\n",
    "        \n",
    "        stage += 1\n",
    "        if stage % 12 == 0:\n",
    "            current_age += 1\n",
    "            if current_age in c.ages_1y: \n",
    "                age_layer = min(age_layer+1, 64)\n",
    "\n",
    "    incidence = inc_log.copy()  # make (14,960)\n",
    "    dead_factor = np.divide(c.N, c.N - pop_log[9:, :].sum(axis=0))  # inc and prev denominator is out of living only\n",
    "    prevalence = np.zeros(pop_log.shape)  # (14,80)\n",
    "\n",
    "    for state in range(14):\n",
    "        incidence[state, :] = np.multiply(incidence[state, :], dead_factor)\n",
    "        prevalence[state, :] = np.multiply(pop_log[state, :], dead_factor)\n",
    "\n",
    "    incidence = incidence.reshape(len(c.health_states), 81, 12).sum(axis=2)  # getting annual incidence (rate per 100k)\n",
    "    incidence_unadj = inc_log.reshape(len(c.health_states), 81, 12).sum(axis=2)  # getting inc unadjusted\n",
    "    prevalence = prevalence.reshape(len(c.health_states), 81, 12).mean(axis=2)  # getting mean annual prevalence\n",
    "    \n",
    "    return incidence, prevalence, incidence_unadj, pop_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(matrix, step_size, num_adj=5):\n",
    "    new_matrix = np.copy(matrix)\n",
    "    step_mat = np.random.choice(len(c.points), size=num_adj, replace=True)\n",
    "    step_age = np.random.choice(13, size=num_adj, replace=True)\n",
    "    small_matrix = new_matrix[2:65:5, :, :]  # (13, 14, 14)\n",
    "\n",
    "    for i in range(num_adj):\n",
    "        (from_state, to_state) = c.points[step_mat[i]]\n",
    "        step_param = (np.mean(small_matrix[:, from_state, to_state]) * step_size).clip(0.00001,0.1)\n",
    "        small_matrix[step_age[i], from_state, to_state] += np.random.uniform(low=-step_param, high=step_param)\n",
    "    \n",
    "    # small_matrix[12,:,:] = np.minimum(small_matrix[11,:],small_matrix[12,:,:])  # Limit potential increase before splining\n",
    "    anchored_matrix = np.concatenate([small_matrix, small_matrix[-1,:,:]], axis=0)\n",
    "    \n",
    "    new_matrix = csaps([22.5,27.5,32.5,37.5,42.5,47.5,52.5,57.5,62.5,67.5,72.5,77.5,82.5,100], anchored_matrix, smooth=0.01, axis=0)(np.arange(20,85,1)).clip(0.0,1.0)\n",
    "    \n",
    "    assert new_matrix.shape[0] == 65\n",
    "    new_matrix = constrain_matrix(new_matrix)\n",
    "    new_matrix = add_acm(new_matrix)\n",
    "    new_matrix = add_csd(new_matrix)\n",
    "    new_matrix = row_normalize(new_matrix)\n",
    "\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_report(iteration, best_eval, best_log, ticker, best_t):\n",
    "    \"\"\"\n",
    "    Prints progress report during simulated annealing.\n",
    "    \"\"\"\n",
    "    _, _, inc_log, _ = best_log\n",
    "    total_dxd = np.sum(inc_log[6:9, :]) / c.N\n",
    "    total_pol = np.sum(inc_log[12, :]) / c.N \n",
    "    print(f\"{iteration}: Best Eval: {best_eval:.5f}, CRC: {total_dxd:.5f}, Polyp: {total_pol:.5f}, Tick: {ticker}\")\n",
    "\n",
    "    if iteration % 25000 == 0:\n",
    "        transition_probs = p.extract_transition_probs(best_t, c.health_states, c.desired_transitions)\n",
    "        print(f\"Detailed Progress Report, Iteration = {iteration}\")\n",
    "        p.print_trans_probs(transition_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(n_iterations, step_size, start_tmat=None, n_adj=7, verbose=False, starting_temp=1, print_interval=2500):\n",
    "    \"\"\"\n",
    "    Performs simulated annealing to optimize a transition matrix.\n",
    "\n",
    "    Args:\n",
    "        n_iterations (int): Number of iterations for optimization.\n",
    "        step_size (float): Step size for parameter adjustments.\n",
    "        start_tmat (numpy.ndarray): Initial transition matrix.\n",
    "        n_adj (int): Number of parameters to adjust per step.\n",
    "        starting_temp (float): Initial temperature for annealing.\n",
    "        verbose (bool): Whether to print progress reports.\n",
    "        print_interval (int): Interval for progress reporting.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Optimized transition matrix.\n",
    "    \"\"\"\n",
    "    best_t = np.copy(start_tmat)\n",
    "    best_log = run_markov(best_t)\n",
    "    best_eval = gof.objective(run_markov(start_tmat), -1)\n",
    "    curr_t, curr_eval = best_t, best_eval\n",
    "    ticker = 0\n",
    "\n",
    "    with tqdm(total=n_iterations, desc=\"Simulated annealing progress\", unit=\"iteration\") as pbar:\n",
    "        \n",
    "        for i in range(n_iterations):\n",
    "\n",
    "            # Run model\n",
    "            candidate_t = np.copy(curr_t)\n",
    "            candidate_t = step(candidate_t, step_size, n_adj)\n",
    "            candidate_log = run_markov(candidate_t)\n",
    "            candidate_eval = gof.objective(candidate_log, i)  # Evaluate candidate point\n",
    "\n",
    "            # Update \"best\" if better than candidate\n",
    "            if candidate_eval < best_eval:\n",
    "                ticker = 0\n",
    "                best_t, best_eval = np.copy(candidate_t), np.copy(candidate_eval)\n",
    "                best_log = run_markov(best_t)\n",
    "\n",
    "            else:\n",
    "                ticker += 1\n",
    "\n",
    "            # Calculate temperature and Metropolis acceptance criterion\n",
    "            t = starting_temp / (1 + np.log(i + 1))\n",
    "            diff = candidate_eval - curr_eval\n",
    "            metropolis = np.exp(-diff / t)\n",
    "\n",
    "            if diff < 0 or np.random.random() < metropolis:\n",
    "                curr_t, curr_eval = np.copy(candidate_t), candidate_eval\n",
    "\n",
    "            # Print progress report\n",
    "            if verbose and i > 0 and i % print_interval == 0:\n",
    "                progress_report(i, best_eval, best_log, ticker, best_t)\n",
    "\n",
    "            # Check if we should update \"curr\"\n",
    "            diff = (candidate_eval - curr_eval)  # difference between candidate and current point evaluation\n",
    "            metropolis = np.exp(-diff / t)  # calculate metropolis acceptance criterion\n",
    "            if (diff < 0 or np.random.random() < metropolis):  # check if we should keep the new point\n",
    "                curr_t, curr_eval = np.copy(candidate_t), np.copy(candidate_eval)  # store the new current point\n",
    "                ticker = 0\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"Final score: \", best_eval)\n",
    "    \n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sa(tmat=None, save_all=False, n_iterations=50000, step_size=0.2, n_adj=5, start_temp=1):\n",
    "    \n",
    "    start_tmat = None\n",
    "    start_tmat = tmat if tmat is not None else create_matrix()   \n",
    "    initial_score = gof.objective(run_markov(start_tmat), -1)\n",
    "    print(f\"Initial score: {round(initial_score, 5)}\")\n",
    "    # print(\"Starting calibration...\")\n",
    "    \n",
    "    result = simulated_annealing(n_iterations=n_iterations, step_size=step_size, start_tmat=tmat, n_adj=n_adj, verbose=True, starting_temp=start_temp)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    \n",
    "    curr_tmat = result.copy()\n",
    "    curr_log = run_markov(curr_tmat)\n",
    "\n",
    "    # Extract transition probabilities\n",
    "    transition_probs = p.extract_transition_probs(curr_tmat, c.health_states, c.desired_transitions)\n",
    "\n",
    "    # Saving\n",
    "    if save_all:\n",
    "        # Save the with the timestamp in the filenames\n",
    "        tmat_path, plot_path, probs_path = c.OUTPUT_PATHS[\"tmats\"], c.OUTPUT_PATHS[\"plots\"], c.OUTPUT_PATHS[\"probs\"]\n",
    "        np.save(f\"{tmat_path}/{timestamp}_tmat.npy\", curr_tmat)\n",
    "\n",
    "        p.print_trans_probs(transition_probs, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.print_trans_probs(transition_probs)\n",
    "        p.plot_tps(curr_tmat, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.plot_vs_seer(curr_log, c.seer_inc, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.plot_vs_seer_total(curr_log, c.seer_inc, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        \n",
    "        out = np.zeros((len(c.points), 65))\n",
    "        for idx, (from_state, to_state) in enumerate(c.points):\n",
    "            out[idx] = curr_tmat[:, from_state, to_state]\n",
    "\n",
    "        pd.DataFrame(out).to_csv(f\"{probs_path}/{timestamp}_tps.csv\")\n",
    "\n",
    "    else:\n",
    "        p.print_trans_probs(transition_probs)\n",
    "        p.plot_tps(curr_tmat)\n",
    "        p.plot_vs_seer(curr_log, c.seer_inc)\n",
    "        p.plot_vs_seer_total(curr_log, c.seer_inc)\n",
    "\n",
    "    return curr_tmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US, SEER:: incidence 1 | polyp 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"{c.model_version}, {c.stage}:: incidence {c.inc_factor} | polyp {c.polyp_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.load(\"../out/US/bc/tmats/20240923_1243_tmat.npy\")\n",
    "result = run_sa(result, True, 10000, 0.2, n_adj=10, start_temp=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective_cp(tmat):\n",
    "    score = 0\n",
    "    cp = cancer_progression(tmat)\n",
    "    score += np.square(cp-3.0).sum()\n",
    "    return score\n",
    "    \n",
    "def cancer_progression(tmat):\n",
    "    \"\"\"\n",
    "    Calculate time from preclinical local to preclinical distant. MFPT\n",
    "    \"\"\"\n",
    "    p_12 = tmat[:, 3, 4] # loc to reg\n",
    "    p_23 = tmat[:, 4, 5] # reg to dis\n",
    "    p_11 = tmat[:, 3, 3] # stay loc\n",
    "    p_22 = tmat[:, 4, 4] # stay reg\n",
    "    p_33 = tmat[:, 5, 5] # stay dis\n",
    "    \n",
    "    cp = (1 + p_12 * (1 + p_23 * (1 / (1 - p_33))) * (1 / (1 - p_22))) * (1 / (1 - p_11))\n",
    "    \n",
    "    return cp\n",
    "    \n",
    "    \n",
    "def sojourn_time_weighted(tm, metric=\"mean\"):\n",
    "    \"\"\"\n",
    "    Calculate  time spent in each path.\n",
    "    \"\"\"\n",
    "    in_loc, in_reg, in_dis = [1/(1-tm[:, x, x]) for x in [3,4,5]]\n",
    "    mloc = in_loc\n",
    "    mreg = in_loc + in_reg\n",
    "    mdis = (in_loc + in_reg * tm[:, 3, 4]) + in_dis\n",
    "    \n",
    "    if metric == \"mean\": # Mean across paths per age \n",
    "        sj_time =  np.mean([mloc, mreg, mdis], axis=0)\n",
    "    else: # Each path per age\n",
    "        sj_time = np.array([mloc, mreg, mdis])\n",
    "    \n",
    "    return sj_time\n",
    "\n",
    "def sojourn_time_weighted2(tm):\n",
    "    \"\"\"\n",
    "    Calculate  time spent in each path, weighted by stage.\n",
    "    \"\"\"\n",
    "    in_loc, in_reg, in_dis = [1/(1-tm[:, x, x]) for x in [3,4,5]]\n",
    "    mloc = in_loc\n",
    "    mreg = in_loc * tm[:, 3, 4] + in_reg\n",
    "    mdis = in_loc * tm[:, 3, 4] + in_reg * tm[:, 4, 5] + in_dis\n",
    "    sj_time = np.array([mloc, mreg, mdis])\n",
    "    \n",
    "    return sj_time\n",
    "\n",
    "def sojourn_time_in_stage(tmat):\n",
    "    \"\"\"\n",
    "    Calculate mean time in each state. Average over all states.\n",
    "    \"\"\"\n",
    "    sojourn_times = np.zeros((3,80))\n",
    "    for i in np.arange(3,6,1):\n",
    "        p_stay = tmat[:, i, i]\n",
    "        sojourn_times[i-3] = 1 / (1 - p_stay)\n",
    "    return sojourn_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmat = np.load(\"../out/US/interp/tmats/20240923_1243_tmat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem, t\n",
    "\n",
    "def summarize_data(data):\n",
    "    \"\"\"\n",
    "    Returns the min, max, median, mean, and 95% confidence interval of a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list or numpy array): Input data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary statistics\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        return \"Data is empty.\"\n",
    "    \n",
    "    # Convert to numpy array for convenience\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Summary statistics\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    median_val = np.median(data)\n",
    "    mean_val = np.mean(data)\n",
    "    \n",
    "    # Compute 95% confidence interval\n",
    "    confidence = 0.95\n",
    "    n = len(data)\n",
    "    if n > 1:\n",
    "        std_err = sem(data)\n",
    "        h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "        ci_lower = mean_val - h\n",
    "        ci_upper = mean_val + h\n",
    "    else:\n",
    "        ci_lower = ci_upper = mean_val  # No confidence interval for a single data point\n",
    "\n",
    "    return {\n",
    "        \"min\": min_val,\n",
    "        \"max\": max_val,\n",
    "        \"median\": median_val,\n",
    "        \"mean\": mean_val,\n",
    "        \"95% CI\": (ci_lower, ci_upper)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, reg, dis = sojourn_time_weighted(tmat, metric=\"\")\n",
    "total = sojourn_time_weighted(tmat)\n",
    "print(summarize_data(loc))\n",
    "print(summarize_data(reg))\n",
    "print(summarize_data(dis))\n",
    "print(summarize_data(total))\n",
    "\n",
    "plt.plot(np.arange(0,80,1), loc, color=\"blue\", label=\"L\")\n",
    "plt.plot(np.arange(0,80,1), reg, color=\"red\", label=\"R\")\n",
    "plt.plot(np.arange(0,80,1), dis, color=\"green\", label=\"D\")\n",
    "plt.plot(np.arange(0,80,1), total, color=\"grey\", label=\"All\")\n",
    "plt.title(\"Sojourn Time by Age (cumulative uL->dX)\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Months\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.hist(loc, bins=30, density=True, alpha=0.6, color=\"blue\", label=\"Loc\")\n",
    "plt.hist(reg, bins=30, density=True, alpha=0.6, color=\"red\", label=\"Reg\")\n",
    "plt.hist(dis, bins=30, density=True, alpha=0.6, color=\"green\", label=\"Dis \")\n",
    "sns.kdeplot(loc, fill=True, color=\"blue\", alpha=0.3, clip=(0, None))  \n",
    "sns.kdeplot(reg, fill=True, color=\"red\", alpha=0.3, clip=(0, None))  \n",
    "sns.kdeplot(dis, fill=True, color=\"green\", alpha=0.3, clip=(0, None))\n",
    "plt.title(\"Density Distribution of Sojourn Time by Stage at DX (cumulative uL->dX)\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, reg, dis = sojourn_time_weighted2(tmat)\n",
    "print(summarize_data(loc))\n",
    "print(summarize_data(reg))\n",
    "print(summarize_data(dis))\n",
    "plt.plot(np.arange(0,80,1), loc, color=\"blue\", label=\"L\")\n",
    "plt.plot(np.arange(0,80,1), reg, color=\"red\", label=\"R\")\n",
    "plt.plot(np.arange(0,80,1), dis, color=\"green\", label=\"D\")\n",
    "plt.title(\"Sojourn Time by Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Months\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(loc, bins=30, density=True, alpha=0.6, color=\"blue\")\n",
    "plt.hist(reg, bins=30, density=True, alpha=0.6, color=\"red\")\n",
    "plt.hist(dis, bins=30, density=True, alpha=0.6, color=\"green\")\n",
    "sns.kdeplot(loc, fill=True, color=\"blue\", alpha=0.3, clip=(0, None), label=\"loc\")  \n",
    "sns.kdeplot(reg, fill=True, color=\"red\", alpha=0.3, clip=(0, None), label=\"reg\")  \n",
    "sns.kdeplot(dis, fill=True, color=\"green\", alpha=0.3, clip=(0, None), label=\"dis\")  \n",
    "plt.title(\"Density Distribution of Sojourn Time\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_data(cancer_progression(tmat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_conditional_probs(matrix):\n",
    "    \"\"\"\n",
    "    Converts a transition matrix into conditional probabilities for TreeAge.\n",
    "    \n",
    "    Parameters:\n",
    "        matrix (numpy.ndarray): Transition matrix of shape (n_ages, n_states, n_states).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Conditional transition matrix of the same shape.\n",
    "    \"\"\"\n",
    "    conditional_matrix = np.copy(matrix)\n",
    "\n",
    "    # Loop through all transitions to adjust probabilities\n",
    "    for (from_idx, to_idx), (from_state, to_state) in zip(c.points, c.desired_transitions): \n",
    "        # Compute survival probability (1 - ACM)\n",
    "        p_survive = 1 - matrix[:, from_idx, c.acm_states[from_idx]].clip(1e-10, 1.0)\n",
    "\n",
    "        # Normalize by survival probability\n",
    "        conditional_matrix[:, from_idx, to_idx] /= p_survive\n",
    "\n",
    "        # If transition is progression (e.g., u_PDAC_x -> u_PDAC_x+1), normalize by p(no_dx)\n",
    "        if from_idx in [3,4,5] and to_idx == from_idx + 1:  # Progression\n",
    "            dx_state = from_idx + 3  # Corresponding diagnosed state\n",
    "            p_no_dx = 1 - matrix[:, from_idx, dx_state].clip(1e-10, 1.0)\n",
    "            conditional_matrix[:, from_idx, to_idx] /= p_no_dx \n",
    "    return conditional_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmat = np.load(\"../out/US/interp/tmats/20240923_1243_tmat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmat_c = convert_to_conditional_probs(tmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transition_probs(tmat, type=\"markov\", metric=\"all\"):\n",
    "    \"\"\"\n",
    "    Extracts and optionally saves transition probabilities from a transition matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        tmat (numpy.ndarray): Transition probability matrix of shape (n_ages, n_states, n_states).\n",
    "        type (str): Type of model (\"markov\" or other). Determines age range.\n",
    "        save (bool): Whether to save the output as a CSV file.\n",
    "        outpath (str): Path to save the CSV file. Required if save=True.\n",
    "        timestamp (str): Custom timestamp for the filename. Defaults to current datetime.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Transition probabilities dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    tmat = convert_to_conditional_probs(tmat) if type == \"treeage\" else tmat\n",
    "    age_range = np.arange(20,100,1)\n",
    "    data = []\n",
    "    df = None \n",
    "    \n",
    "    if metric == \"all\":\n",
    "        for (from_idx, to_idx), (from_state, to_state) in zip(c.points, c.desired_transitions):\n",
    "            for age, probs in zip(age_range, tmat[:, from_idx, to_idx]):\n",
    "                data.append({\n",
    "                    \"Age\": age,\n",
    "                    \"From State\": from_state,\n",
    "                    \"To State\": to_state,\n",
    "                    \"Probability\": probs\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    elif metric == \"avg\":\n",
    "        for (from_idx, to_idx), (from_state, to_state) in c.transitions_itos.items():\n",
    "            probs = [round(p,5) for p in tmat[:, from_idx, to_idx]]\n",
    "            data.append({\n",
    "                \"From State\": from_state,\n",
    "                \"To State\": to_state,\n",
    "                \"Age 30\": probs[10],\n",
    "                \"Age 75\": probs[-10],\n",
    "                 \"Min\": min(probs),\n",
    "                 \"Max\": max(probs),\n",
    "                 \"Avg\": round(np.mean(probs),5)\n",
    "            })\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    else:\n",
    "        print(\"Wrong metric specified in extract_transition_probs. Need [avg, all]\")\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_transition_probs(tmat_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../out/US/interp/probs/20240923_1243_c.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drcrc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
