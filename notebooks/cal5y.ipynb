{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR CRC Calibration\n",
    "\n",
    "Author: Sophie Wagner, sw3767@cumc.columbia.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "import numpy as np  # For matrix manipulation\n",
    "import pandas as pd  # For output/input data processing\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "from csaps import csaps\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Load .py files\n",
    "import common_functions as func\n",
    "import calibration_plots as p\n",
    "import configs as c\n",
    "import gof\n",
    "\n",
    "\n",
    "# Some aesthetic options\n",
    "np.set_printoptions(suppress=True, linewidth=300, formatter={'float': '{: 0.9f}'.format})\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix setup, normalization, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_normalize(matrix):\n",
    "    for age_layer in range(matrix.shape[0]):  # Loop over each age layer\n",
    "        layer = matrix[age_layer]\n",
    "        # Calculate the sum of non-diagonal elements for each row\n",
    "        sum_of_columns = np.sum(layer, axis=1) - np.diag(layer)\n",
    "        # Set the diagonal elements\n",
    "        np.fill_diagonal(layer, 1 - sum_of_columns)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def create_matrix():\n",
    "    matrix = np.zeros((len(c.age_layers), len(c.health_states), len(c.health_states)))\n",
    "    matrix[:, 0, 1] = func.probtoprob(0.005)  # Healthy to LR\n",
    "    matrix[:, 1, 2] = func.probtoprob(0.015)  # LR to HR\n",
    "    matrix[:, 2, 3] = func.probtoprob(0.05)  # HR to uLoc\n",
    "    matrix[:, 3, 4] = func.probtoprob(0.45)  # uLoc to uReg\n",
    "    matrix[:, 4, 5] = func.probtoprob(0.50)  # uReg to uDis\n",
    "    matrix[:, 3, 6] = func.probtoprob(0.20)  # uLoc to dLoc\n",
    "    matrix[:, 4, 7] = func.probtoprob(0.60)  # uReg to dReg\n",
    "    matrix[:, 5, 8] = func.probtoprob(0.90)  # uDis to dDis\n",
    "\n",
    "    matrix = add_acm(matrix)  # ACM\n",
    "    matrix = add_csd(matrix)  # CSD\n",
    "    matrix = constrain_matrix(matrix)  # constrain\n",
    "    matrix = row_normalize(matrix)  # normalize\n",
    "\n",
    "    return matrix\n",
    "\n",
    "locreg=func.probtoprob(0.1)\n",
    "def constrain_matrix(matrix):\n",
    "    matrix = np.clip(matrix, 0.0, 0.5)\n",
    "\n",
    "    # Progression Block\n",
    "    matrix[:, 0, 1] = np.maximum(0.000001, matrix[:, 0, 1])  # not below 0\n",
    "    matrix[:, 1, 2] = np.maximum(matrix[:, 0, 1], matrix[:, 1, 2])  \n",
    "    matrix[:, 2, 3] = np.maximum(matrix[:, 1, 2], matrix[:, 2, 3])\n",
    "    matrix[:, 3, 4] = np.maximum(locreg, matrix[:, 3, 4])\n",
    "    matrix[:, 3, 4] = np.maximum(matrix[:, 2, 3], matrix[:, 3, 4])\n",
    "    matrix[:, 4, 5] = np.maximum(matrix[:, 3, 4], matrix[:, 4, 5])\n",
    "\n",
    "    # Detection Block\n",
    "    matrix[:, 3, 6] = np.maximum(0.000001, matrix[:, 3, 6])\n",
    "    matrix[:, 4, 7] = np.maximum(matrix[:, 3, 6], matrix[:, 4, 7])\n",
    "    matrix[:, 5, 8] = np.maximum(matrix[:, 4, 7], matrix[:, 5, 8])\n",
    "    \n",
    "    # Age dependencies\n",
    "    matrix[:, 0, 1] = np.maximum.accumulate(matrix[:,0,1])\n",
    "    # matrix[:, 1, 2] = np.maximum.accumulate(matrix[:,0,1])\n",
    "    # matrix[:, 2, 3] = np.maximum.accumulate(matrix[:,0,1])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_acm(matrix):\n",
    "    matrix[:, 0, 10] = c.acm_rate  # Healthy to ACM\n",
    "    matrix[:, 1:3, 12] = c.acm_rate[:, np.newaxis]  # Polyp to ACM\n",
    "    matrix[:, 3:6, 13] = c.acm_rate[:, np.newaxis]  # Undiagnosed to ACM\n",
    "    matrix[:, 6:9, 11] = c.acm_rate[:, np.newaxis]  # Cancer to ACM\n",
    "    matrix[:, 9, 9] = 1  # Stay in CSD\n",
    "    matrix[:, 10, 10] = 1  # Stay in ACM\n",
    "    matrix[:, 11, 11] = 1  # Stay in Cancer ACM\n",
    "    matrix[:, 12, 12] = 1  # Stay in Polyp ACM\n",
    "    matrix[:, 13, 13] = 1  # Stay in uCRC ACM\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_csd(matrix):\n",
    "    matrix[:, 6, 9] = c.csd_rate[:, 0]\n",
    "    matrix[:, 7, 9] = c.csd_rate[:, 1]\n",
    "    matrix[:, 8, 9] = c.csd_rate[:, 2]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_markov(matrix, starting_age=20, max_age=84):\n",
    "    \n",
    "    current_age = starting_age\n",
    "    stage, age_layer = 1, 0\n",
    "    month_pop, pop_log = c.starting_pop, c.starting_pop\n",
    "    inc_log = np.zeros(pop_log.shape)  # to track new incidences in each state\n",
    "    matrixT = matrix.transpose(0,2,1)\n",
    "    inflow_matrix = np.tril(matrixT, k=-1)\n",
    "    \n",
    "    while current_age <= max_age:\n",
    "        \n",
    "        # Matrix multiplication (state transition)\n",
    "        mat, inflow_mat = matrixT[age_layer], inflow_matrix[age_layer] \n",
    "        month_inc = np.matmul(inflow_mat, month_pop)  # (9, 9)(9, 1)->(9, 1)\n",
    "        month_pop = np.matmul(mat, month_pop)  # (9, 9)(9, 1)->(9, 1)\n",
    "        \n",
    "        # Add to log\n",
    "        inc_log = np.concatenate((inc_log, month_inc), axis=1)\n",
    "        pop_log = np.concatenate((pop_log, month_pop), axis=1)\n",
    "        \n",
    "        stage += 1\n",
    "        if stage % 12 == 0:\n",
    "            current_age += 1\n",
    "            if current_age in c.ages_5y: \n",
    "                age_layer = min(age_layer+1, 12)\n",
    "\n",
    "    incidence = inc_log.copy()  # make (14,780)\n",
    "    dead_factor = np.divide(c.N, c.N - pop_log[9:, :].sum(axis=0))  # inc and prev denominator is out of living only\n",
    "    prevalence = np.zeros(pop_log.shape)  # (14,65)\n",
    "\n",
    "    for state in range(14):\n",
    "        incidence[state, :] = np.multiply(incidence[state, :], dead_factor)\n",
    "        prevalence[state, :] = np.multiply(pop_log[state, :], dead_factor)\n",
    "\n",
    "    incidence = incidence.reshape(len(c.health_states), 65, 12).sum(axis=2)  # getting annual incidence (rate per 100k)\n",
    "    incidence_unadj = inc_log.reshape(len(c.health_states), 65, 12).sum(axis=2)  # getting inc unadjusted\n",
    "    prevalence = prevalence.reshape(len(c.health_states), 65, 12).mean(axis=2)  # getting mean annual prevalence\n",
    "    \n",
    "    return incidence, prevalence, incidence_unadj, pop_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mids = [22.5,27.5,32.5,37.5,42.5,47.5,52.5,57.5,62.5,67.5,72.5,77.5,82.5]\n",
    "def step(matrix, step_size, num_adj=5):\n",
    "    new_matrix = np.copy(matrix)\n",
    "    step_mat = np.random.choice(len(c.points), size=num_adj, replace=True)\n",
    "    step_age = np.random.choice(len(c.age_layers_5y), size=num_adj, replace=True)\n",
    "\n",
    "    for i in range(num_adj):\n",
    "        (from_state, to_state) = c.points[step_mat[i]]\n",
    "        step_param = np.mean(new_matrix[:, from_state, to_state]) * step_size\n",
    "        new_matrix[step_age[i], from_state, to_state] += np.random.uniform(low=-step_param, high=step_param)\n",
    "    \n",
    "    new_matrix[12,:,:] = np.minimum(new_matrix[11,:],new_matrix[12,:,:])  # Limit potential increase before splining\n",
    "    new_matrix = csaps(age_mids, new_matrix, smooth=0.01, axis=0)(age_mids).clip(0.0,1.0)\n",
    "    \n",
    "    new_matrix = constrain_matrix(new_matrix)\n",
    "    new_matrix = add_acm(new_matrix)\n",
    "    new_matrix = add_csd(new_matrix)\n",
    "    new_matrix = row_normalize(new_matrix)\n",
    "\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_report(iteration, best_eval, best_log, ticker, best_t):\n",
    "    \"\"\"\n",
    "    Prints progress report during simulated annealing.\n",
    "    \"\"\"\n",
    "    log_adj, _, inc_log, _ = best_log\n",
    "    total_dxd = np.sum(inc_log[6:9, :]) / c.N\n",
    "    total_pol = np.sum(inc_log[12, :]) / c.N \n",
    "    print(f\"{iteration}: Best Eval: {best_eval:.5f}, CRC: {total_dxd:.5f}, Polyp: {total_pol:.5f}, Tick: {ticker}\")\n",
    "\n",
    "    if iteration % 50000 == 0:\n",
    "        transition_probs = p.extract_transition_probs(best_t, c.health_states, c.desired_transitions)\n",
    "        print(f\"Detailed Progress Report, Iteration = {iteration}\")\n",
    "        p.print_trans_probs(transition_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(n_iterations, step_size, start_tmat=None, n_adj=7, verbose=False, starting_temp=1, print_interval=2500, obj=\"\"):\n",
    "    \"\"\"\n",
    "    Performs simulated annealing to optimize a transition matrix.\n",
    "\n",
    "    Args:\n",
    "        n_iterations (int): Number of iterations for optimization.\n",
    "        step_size (float): Step size for parameter adjustments.\n",
    "        start_tmat (numpy.ndarray): Initial transition matrix.\n",
    "        n_adj (int): Number of parameters to adjust per step.\n",
    "        starting_temp (float): Initial temperature for annealing.\n",
    "        verbose (bool): Whether to print progress reports.\n",
    "        print_interval (int): Interval for progress reporting.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Optimized transition matrix.\n",
    "    \"\"\"\n",
    "    best_t = np.copy(start_tmat)\n",
    "    best_log = run_markov(best_t)\n",
    "    best_eval = gof.objective(run_markov(start_tmat), -1, obj)\n",
    "    curr_t, curr_eval = best_t, best_eval\n",
    "    ticker = 0\n",
    "\n",
    "    with tqdm(total=n_iterations, desc=\"Simulated annealing progress\", unit=\"iteration\") as pbar:\n",
    "        \n",
    "        for i in range(n_iterations):\n",
    "\n",
    "            # Run model\n",
    "            candidate_t = np.copy(curr_t)\n",
    "            candidate_t = step(candidate_t, step_size, n_adj)\n",
    "            candidate_log = run_markov(candidate_t)\n",
    "            candidate_eval = gof.objective(candidate_log, i, obj)  # Evaluate candidate point\n",
    "\n",
    "            # Update \"best\" if better than candidate\n",
    "            if candidate_eval < best_eval:\n",
    "                ticker = 0\n",
    "                best_t, best_eval = np.copy(candidate_t), np.copy(candidate_eval)\n",
    "                best_log = run_markov(best_t)\n",
    "\n",
    "            else:\n",
    "                ticker += 1\n",
    "\n",
    "            # Calculate temperature and Metropolis acceptance criterion\n",
    "            t = starting_temp / (1 + np.log(i + 1))\n",
    "            diff = candidate_eval - curr_eval\n",
    "            metropolis = np.exp(-diff / t)\n",
    "\n",
    "            if diff < 0 or np.random.random() < metropolis:\n",
    "                curr_t, curr_eval = np.copy(candidate_t), candidate_eval\n",
    "\n",
    "            # Print progress report\n",
    "            if verbose and i > 0 and i % print_interval == 0:\n",
    "                progress_report(i, best_eval, best_log, ticker, best_t)\n",
    "\n",
    "            # Check if we should update \"curr\"\n",
    "            diff = (candidate_eval - curr_eval)  # difference between candidate and current point evaluation\n",
    "            metropolis = np.exp(-diff / t)  # calculate metropolis acceptance criterion\n",
    "            if (diff < 0 or np.random.random() < metropolis):  # check if we should keep the new point\n",
    "                curr_t, curr_eval = np.copy(candidate_t), np.copy(candidate_eval)  # store the new current point\n",
    "                ticker = 0\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(\"Final score: \", best_eval)\n",
    "    \n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sa(tmat=None, save_all=False, n_iterations=50000, step_size=0.2, n_adj=5, starting_temp=1, obj=\"\"):\n",
    "    \n",
    "    start_tmat = None\n",
    "    start_tmat = tmat if tmat is not None else create_matrix()   \n",
    "    initial_score = gof.objective(run_markov(start_tmat), -1, obj)\n",
    "    print(f\"Initial score: {round(initial_score, 5)}\")\n",
    "    # print(\"Starting calibration...\")\n",
    "    \n",
    "    result = simulated_annealing(n_iterations=n_iterations, step_size=step_size, start_tmat=tmat, n_adj=n_adj, starting_temp=starting_temp, verbose=True, obj=obj)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    \n",
    "    curr_tmat = result.copy()\n",
    "    curr_log = run_markov(curr_tmat)\n",
    "\n",
    "    # Extract transition probabilities\n",
    "    transition_probs = p.extract_transition_probs(curr_tmat, c.health_states, c.desired_transitions)\n",
    "\n",
    "    # Saving\n",
    "    if save_all:\n",
    "        # Save the with the timestamp in the filenames\n",
    "        tmat_path, plot_path, probs_path = c.OUTPUT_PATHS[\"tmats\"], c.OUTPUT_PATHS[\"plots\"], c.OUTPUT_PATHS[\"probs\"]\n",
    "        np.save(f\"{tmat_path}/{timestamp}_tmat.npy\", curr_tmat)\n",
    "\n",
    "        p.print_trans_probs(transition_probs, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.print_trans_probs(transition_probs)\n",
    "        p.plot_tps(curr_tmat, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.plot_vs_seer(curr_log, c.seer_inc, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.plot_vs_seer_total(curr_log, c.seer_inc, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        \n",
    "        out = np.zeros((len(c.points), 80))\n",
    "        for idx, (from_state, to_state) in enumerate(c.points):\n",
    "            out[idx] = curr_tmat[:, from_state, to_state]\n",
    "\n",
    "        pd.DataFrame(out).to_csv(f\"{probs_path}/{timestamp}_tps.csv\")\n",
    "\n",
    "    # else:\n",
    "        # p.print_trans_probs(transition_probs)\n",
    "        # p.plot_tps(curr_tmat)\n",
    "        # p.plot_vs_seer(curr_log, c.seer_inc)\n",
    "        # p.plot_vs_seer_total(curr_log, c.seer_inc)\n",
    "\n",
    "    return curr_tmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective_cp(tmat):\n",
    "    score = 0\n",
    "    cp = cancer_progression(tmat)\n",
    "    score += np.square(cp-3.0).sum()\n",
    "    return score\n",
    "    \n",
    "def cancer_progression(tmat):\n",
    "    \"\"\"\n",
    "    Calculate time from preclinical local to preclinical distant. MFPT\n",
    "    \"\"\"\n",
    "    p_12 = tmat[:, 3, 4] # loc to reg\n",
    "    p_23 = tmat[:, 4, 5] # reg to dis\n",
    "    p_11 = tmat[:, 3, 3] # stay loc\n",
    "    p_22 = tmat[:, 4, 4] # stay reg\n",
    "    p_33 = tmat[:, 5, 5] # stay dis\n",
    "    \n",
    "    cp = (1 + p_12 * (1 + p_23 * (1 / (1 - p_33))) * (1 / (1 - p_22))) * (1 / (1 - p_11))\n",
    "    \n",
    "    return cp\n",
    "    \n",
    "    \n",
    "def sojourn_time_weighted(tm, metric=\"mean\"):\n",
    "    \"\"\"\n",
    "    Calculate  time spent in each path.\n",
    "    \"\"\"\n",
    "    in_loc, in_reg, in_dis = [1/(1-tm[:, x, x]) for x in [3,4,5]]\n",
    "    mloc = in_loc\n",
    "    mreg = in_loc + in_reg\n",
    "    mdis = (in_loc + in_reg * tm[:, 3, 4]) + in_dis\n",
    "    \n",
    "    if metric == \"mean\": # Mean across paths per age \n",
    "        sj_time =  np.mean([mloc, mreg, mdis], axis=0)\n",
    "    else: # Each path per age\n",
    "        sj_time = np.array([mloc, mreg, mdis])\n",
    "    \n",
    "    return sj_time\n",
    "\n",
    "def sojourn_time_weighted2(tm):\n",
    "    \"\"\"\n",
    "    Calculate  time spent in each path, weighted by stage.\n",
    "    \"\"\"\n",
    "    in_loc, in_reg, in_dis = [1/(1-tm[:, x, x]) for x in [3,4,5]]\n",
    "    mloc = in_loc\n",
    "    mreg = in_loc * tm[:, 3, 4] + in_reg\n",
    "    mdis = in_loc * tm[:, 3, 4] + in_reg * tm[:, 4, 5] + in_dis\n",
    "    sj_time = np.array([mloc, mreg, mdis])\n",
    "    \n",
    "    return sj_time\n",
    "\n",
    "def sojourn_time_in_stage(tmat):\n",
    "    \"\"\"\n",
    "    Calculate mean time in each state. Average over all states.\n",
    "    \"\"\"\n",
    "    sojourn_times = np.zeros((3,80))\n",
    "    for i in np.arange(3,6,1):\n",
    "        p_stay = tmat[:, i, i]\n",
    "        sojourn_times[i-3] = 1 / (1 - p_stay)\n",
    "    return sojourn_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem, t\n",
    "\n",
    "def summarize_data(data):\n",
    "    \"\"\"\n",
    "    Returns the min, max, median, mean, and 95% confidence interval of a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list or numpy array): Input data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary statistics\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        return \"Data is empty.\"\n",
    "    \n",
    "    # Convert to numpy array for convenience\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Summary statistics\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    median_val = np.median(data)\n",
    "    mean_val = np.mean(data)\n",
    "    \n",
    "    # Compute 95% confidence interval\n",
    "    confidence = 0.95\n",
    "    n = len(data)\n",
    "    if n > 1:\n",
    "        std_err = sem(data)\n",
    "        h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "        ci_lower = mean_val - h\n",
    "        ci_upper = mean_val + h\n",
    "    else:\n",
    "        ci_lower = ci_upper = mean_val  # No confidence interval for a single data point\n",
    "\n",
    "    return {\n",
    "        \"min\": min_val,\n",
    "        \"max\": max_val,\n",
    "        \"median\": median_val,\n",
    "        \"mean\": mean_val,\n",
    "        \"95% CI\": (ci_lower, ci_upper)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, reg, dis = sojourn_time_weighted(tmat, metric=\"\")\n",
    "total = sojourn_time_weighted(tmat)\n",
    "print(summarize_data(loc))\n",
    "print(summarize_data(reg))\n",
    "print(summarize_data(dis))\n",
    "print(summarize_data(total))\n",
    "\n",
    "plt.plot(np.arange(0,80,1), loc, color=\"blue\", label=\"L\")\n",
    "plt.plot(np.arange(0,80,1), reg, color=\"red\", label=\"R\")\n",
    "plt.plot(np.arange(0,80,1), dis, color=\"green\", label=\"D\")\n",
    "plt.plot(np.arange(0,80,1), total, color=\"grey\", label=\"All\")\n",
    "plt.title(\"Sojourn Time by Age (cumulative uL->dX)\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Months\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.hist(loc, bins=30, density=True, alpha=0.6, color=\"blue\", label=\"Loc\")\n",
    "plt.hist(reg, bins=30, density=True, alpha=0.6, color=\"red\", label=\"Reg\")\n",
    "plt.hist(dis, bins=30, density=True, alpha=0.6, color=\"green\", label=\"Dis \")\n",
    "sns.kdeplot(loc, fill=True, color=\"blue\", alpha=0.3, clip=(0, None))  \n",
    "sns.kdeplot(reg, fill=True, color=\"red\", alpha=0.3, clip=(0, None))  \n",
    "sns.kdeplot(dis, fill=True, color=\"green\", alpha=0.3, clip=(0, None))\n",
    "plt.title(\"Density Distribution of Sojourn Time by Stage at DX (cumulative uL->dX)\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend Parameters to Age 100\n",
    "\n",
    "- Use cubic spline interpolation to interpolate probabilities from 20-100\n",
    "- Anchor increasing parameters at age 100 to prevent exponential incidence increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_tmat(mat, save=False, outpath=\"\", timestamp=\"\"):\n",
    "    \n",
    "    # Interpolation without anchoring\n",
    "    tmat = csaps(age_mids, mat, smooth=0.01, axis=2)(np.linspace(20,100,81)) \n",
    "    \n",
    "    # Anchor with mean at 100 (if mean < last age bucket value) and Smooth interpolation over age\n",
    "    tmat_anchored = np.concatenate([mat, np.minimum(mat[-1:, :, :], np.mean(mat, axis=0, keepdims=True))], axis=0)\n",
    "    tmat_anchored = csaps([25,35,45,52.5,57.5,62.5,67.5,72.5,77.5,82.5, 100], tmat_anchored, smooth=0.01, axis=2)(np.linspace(18,100,83)).clip(0.0, 1.0)\n",
    "\n",
    "    # If smoothed tmat is exp increasing towards end, used anchored probs\n",
    "    increasing_at_100 = tmat[-2:-1, :, :] < tmat[-1:, :, :]\n",
    "    tmat_anchored = np.where(increasing_at_100, tmat_anchored, tmat)\n",
    "    transition_mask = np.zeros((14, 14), dtype=bool)\n",
    "    from_states, to_states = zip(*c.points)\n",
    "    transition_mask[from_states, to_states] = True\n",
    "    tmat_anchored = np.where(increasing_at_100 & transition_mask[np.newaxis, ...], tmat_anchored, tmat)\n",
    "\n",
    "    tmat = tmat_anchored\n",
    "    \n",
    "    # HANDLE NEGATIVE CASE: Sometimes spline dips below 0 and becomes positive again, causing a spike after clipping the matrix to 0 and 1.\n",
    "    # Find the index of the first negative before a positive index from the last age\n",
    "    neg_after_pos = ((tmat[:, :, :-1, :, :] >= 0) & (tmat[:, :, 1:, :, :] < 0)) # any negative after positive marked True\n",
    "    neg_after_pos = np.insert(neg_after_pos, 0, False, axis=0) # insert False at the first index to make arr shape same as tmat, by definition first idx is False\n",
    "    neg_after_pos_reversed = np.flip(neg_after_pos, axis=0)\n",
    "    last_neg_after_pos_til_end = np.flip(np.where(np.cumsum(neg_after_pos_reversed, axis=0) == 0, True, neg_after_pos_reversed), axis=0) # reverse to find the last True, set values from last True until end to True\n",
    "    mask = np.any(neg_after_pos, axis=2).reshape(2, 2, 1, 18, 18) & last_neg_after_pos_til_end # only apply this to indices that have negative at the end\n",
    "    # Set indices from last negative after positive to end to zero\n",
    "    tmat[mask] = 0\n",
    "\n",
    "    tmat = row_normalize(tmat)\n",
    "\n",
    "    if save:\n",
    "      os.makedirs(outpath, exist_ok=True)\n",
    "      # Save tmat\n",
    "      np.save(f\"{outpath}/{timestamp}_100.npy\", tmat)\n",
    "    return tmat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drcrc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
