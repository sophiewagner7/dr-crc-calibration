{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR CRC Calibration\n",
    "\n",
    "Author: Sophie Wagner, sw3767@cumc.columbia.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "import numpy as np  # For matrix manipulation\n",
    "import pandas as pd  # For output/input data processing\n",
    "import matplotlib.pyplot as plt  # For visualizations\n",
    "from csaps import csaps\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Load .py files\n",
    "import common_functions as func\n",
    "import calibration_plots as p\n",
    "import configs as c\n",
    "import gof\n",
    "\n",
    "\n",
    "# Some aesthetic options\n",
    "np.set_printoptions(suppress=True, linewidth=300, formatter={'float': '{: 0.9f}'.format})\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix setup, normalization, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_normalize(matrix):\n",
    "    for age_layer in range(matrix.shape[0]):  # Loop over each age layer\n",
    "        layer = matrix[age_layer]\n",
    "        # Calculate the sum of non-diagonal elements for each row\n",
    "        sum_of_columns = np.sum(layer, axis=1) - np.diag(layer)\n",
    "        # Set the diagonal elements\n",
    "        np.fill_diagonal(layer, 1 - sum_of_columns)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def create_matrix():\n",
    "    matrix = np.zeros((len(c.age_layers), len(c.health_states), len(c.health_states)))\n",
    "    matrix[:, 0, 1] = func.probtoprob(0.005)  # Healthy to LR\n",
    "    matrix[:, 1, 2] = func.probtoprob(0.015)  # LR to HR\n",
    "    matrix[:, 2, 3] = func.probtoprob(0.05)  # HR to uLoc\n",
    "    matrix[:, 3, 4] = func.probtoprob(0.45)  # uLoc to uReg\n",
    "    matrix[:, 4, 5] = func.probtoprob(0.50)  # uReg to uDis\n",
    "    matrix[:, 3, 6] = func.probtoprob(0.20)  # uLoc to dLoc\n",
    "    matrix[:, 4, 7] = func.probtoprob(0.60)  # uReg to dReg\n",
    "    matrix[:, 5, 8] = func.probtoprob(0.90)  # uDis to dDis\n",
    "\n",
    "    matrix = add_acm(matrix)  # ACM\n",
    "    matrix = add_csd(matrix)  # CSD\n",
    "    matrix = constrain_matrix(matrix)  # constrain\n",
    "    matrix = row_normalize(matrix)  # normalize\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def constrain_matrix(matrix):\n",
    "    matrix = np.clip(matrix, 0.0, 0.5)\n",
    "\n",
    "    # Progression Block\n",
    "    matrix[:, 0, 1] = np.maximum(0.000001, matrix[:, 0, 1])  # not below 0\n",
    "    matrix[:, 1, 2] = np.maximum(matrix[:, 0, 1], matrix[:, 1, 2])  \n",
    "    matrix[:, 2, 3] = np.maximum(matrix[:, 1, 2], matrix[:, 2, 3])\n",
    "    matrix[:, 3, 4] = np.maximum(matrix[:, 2, 3], matrix[:, 3, 4])\n",
    "    matrix[:, 4, 5] = np.maximum(matrix[:, 3, 4], matrix[:, 4, 5])\n",
    "\n",
    "    # Detection Block\n",
    "    matrix[:, 3, 6] = np.maximum(0.000001, matrix[:, 3, 6])\n",
    "    matrix[:, 4, 7] = np.maximum(matrix[:, 3, 6], matrix[:, 4, 7])\n",
    "    matrix[:, 5, 8] = np.maximum(matrix[:, 4, 7], matrix[:, 5, 8])\n",
    "    \n",
    "    # Age dependencies\n",
    "    # matrix[:, 0, 1] = np.maximum.accumulate(matrix[:,0,1])\n",
    "    # matrix[:, 1, 2] = np.maximum.accumulate(matrix[:,0,1])\n",
    "    # matrix[:, 2, 3] = np.maximum.accumulate(matrix[:,0,1])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_acm(matrix):\n",
    "    matrix[:, 0, 10] = c.acm_rate  # Healthy to ACM\n",
    "    matrix[:, 1:3, 12] = c.acm_rate[:, np.newaxis]  # Polyp to ACM\n",
    "    matrix[:, 3:6, 13] = c.acm_rate[:, np.newaxis]  # Undiagnosed to ACM\n",
    "    matrix[:, 6:9, 11] = c.acm_rate[:, np.newaxis]  # Cancer to ACM\n",
    "    matrix[:, 9, 9] = 1  # Stay in CSD\n",
    "    matrix[:, 10, 10] = 1  # Stay in ACM\n",
    "    matrix[:, 11, 11] = 1  # Stay in Cancer ACM\n",
    "    matrix[:, 12, 12] = 1  # Stay in Polyp ACM\n",
    "    matrix[:, 13, 13] = 1  # Stay in uCRC ACM\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def add_csd(matrix):\n",
    "    matrix[:, 6, 9] = c.csd_rate[:, 0]\n",
    "    matrix[:, 7, 9] = c.csd_rate[:, 1]\n",
    "    matrix[:, 8, 9] = c.csd_rate[:, 2]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_markov(matrix, starting_age=20, max_age=100):\n",
    "    \n",
    "    current_age = starting_age\n",
    "    stage, age_layer = 1, 0\n",
    "    month_pop, pop_log = c.starting_pop, c.starting_pop\n",
    "    inc_log = np.zeros(pop_log.shape)  # to track new incidences in each state\n",
    "    matrixT = matrix.transpose(0,2,1)\n",
    "    inflow_matrix = np.tril(matrixT, k=-1)\n",
    "    \n",
    "    while current_age <= max_age:\n",
    "        \n",
    "        # Matrix multiplication (state transition)\n",
    "        mat, inflow_mat = matrixT[age_layer], inflow_matrix[age_layer] \n",
    "        month_inc = np.matmul(inflow_mat, month_pop)  # (9, 9)(9, 1)->(9, 1)\n",
    "        month_pop = np.matmul(mat, month_pop)  # (9, 9)(9, 1)->(9, 1)\n",
    "        \n",
    "        # Add to log\n",
    "        inc_log = np.concatenate((inc_log, month_inc), axis=1)\n",
    "        pop_log = np.concatenate((pop_log, month_pop), axis=1)\n",
    "        \n",
    "        stage += 1\n",
    "        if stage % 12 == 0:\n",
    "            current_age += 1\n",
    "            age_layer = min(age_layer+1, 79)\n",
    "\n",
    "    incidence = inc_log.copy()  # make (14,960)\n",
    "    dead_factor = np.divide(c.N, c.N - pop_log[9:, :].sum(axis=0))  # inc and prev denominator is out of living only\n",
    "    prevalence = np.zeros(pop_log.shape)  # (14,80)\n",
    "\n",
    "    for state in range(14):\n",
    "        incidence[state, :] = np.multiply(incidence[state, :], dead_factor)\n",
    "        prevalence[state, :] = np.multiply(pop_log[state, :], dead_factor)\n",
    "\n",
    "    incidence = incidence.reshape(len(c.health_states), 81, 12).sum(axis=2)  # getting annual incidence (rate per 100k)\n",
    "    incidence_unadj = inc_log.reshape(len(c.health_states), 81, 12).sum(axis=2)  # getting inc unadjusted\n",
    "    prevalence = prevalence.reshape(len(c.health_states), 81, 12).mean(axis=2)  # getting mean annual prevalence\n",
    "    \n",
    "    return incidence, prevalence, incidence_unadj, pop_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(matrix, step_size, num_adj=5):\n",
    "    new_matrix = np.copy(matrix)\n",
    "    step_mat = np.random.choice(len(c.points), size=num_adj, replace=True)\n",
    "    step_age = np.random.choice(len(c.age_layers_5y), size=num_adj, replace=True)\n",
    "    small_matrix = new_matrix[2:65:5, :, :]  # (13, 14, 14)\n",
    "\n",
    "    for i in range(num_adj):\n",
    "        (from_state, to_state) = c.points[step_mat[i]]\n",
    "        step_param = np.mean(small_matrix[:, from_state, to_state]) * step_size\n",
    "        small_matrix[step_age[i], from_state, to_state] += np.random.uniform(low=-step_param, high=step_param)\n",
    "    \n",
    "    # anchor = small_matrix[:,:,:].mean(axis=0)  # Mean accross ages\n",
    "    # anchored_matrix = np.append(small_matrix, anchor, axis=0)  # add final age to axis 0 ages\n",
    "    small_matrix[12,:,:] = np.minimum(small_matrix[11,:],small_matrix[12,:,:])  # Limit potential increase before splining\n",
    "    new_matrix = csaps([22.5,27.5,32.5,37.5,42.5,47.5,52.5,57.5,62.5,67.5,72.5,77.5,82.5], small_matrix, smooth=0.01, axis=0)(np.arange(20,100,1)).clip(0.0,1.0)\n",
    "    new_matrix = constrain_matrix(new_matrix)\n",
    "    new_matrix = add_acm(new_matrix)\n",
    "    new_matrix = add_csd(new_matrix)\n",
    "    new_matrix = row_normalize(new_matrix)\n",
    "\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_report(iteration, best_eval, best_log, ticker, best_t):\n",
    "    \"\"\"\n",
    "    Prints progress report during simulated annealing.\n",
    "    \"\"\"\n",
    "    log_adj, _, inc_log, _ = best_log\n",
    "    total_dxd = np.sum(inc_log[6:9, :]) / c.N\n",
    "    print(f\"{iteration}: Best Eval: {best_eval:.5f}, CRC: {total_dxd:.5f}, Tick: {ticker}\")\n",
    "\n",
    "    if iteration % 50000 == 0:\n",
    "        transition_probs = p.extract_transition_probs(best_t, c.health_states, c.desired_transitions)\n",
    "        print(f\"Detailed Progress Report, Iteration = {iteration}\")\n",
    "        p.print_trans_probs(transition_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(n_iterations, step_size, start_tmat=None, n_adj=7, verbose=False, starting_temp=1, print_interval=2500, obj=\"\"):\n",
    "    \"\"\"\n",
    "    Performs simulated annealing to optimize a transition matrix.\n",
    "\n",
    "    Args:\n",
    "        n_iterations (int): Number of iterations for optimization.\n",
    "        step_size (float): Step size for parameter adjustments.\n",
    "        start_tmat (numpy.ndarray): Initial transition matrix.\n",
    "        n_adj (int): Number of parameters to adjust per step.\n",
    "        starting_temp (float): Initial temperature for annealing.\n",
    "        verbose (bool): Whether to print progress reports.\n",
    "        print_interval (int): Interval for progress reporting.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Optimized transition matrix.\n",
    "    \"\"\"\n",
    "    best_t = np.copy(start_tmat)\n",
    "    best_log = run_markov(best_t)\n",
    "    best_eval = gof.objective(run_markov(start_tmat), -1, obj)\n",
    "    curr_t, curr_eval = best_t, best_eval\n",
    "    ticker = 0\n",
    "\n",
    "    with tqdm(total=n_iterations, desc=\"Simulated annealing progress\", unit=\"iteration\") as pbar:\n",
    "        \n",
    "        for i in range(n_iterations):\n",
    "\n",
    "            # Run model\n",
    "            candidate_t = np.copy(curr_t)\n",
    "            candidate_t = step(candidate_t, step_size, n_adj)\n",
    "            candidate_log = run_markov(candidate_t)\n",
    "            candidate_eval = gof.objective(candidate_log, i, obj)  # Evaluate candidate point\n",
    "\n",
    "            # Update \"best\" if better than candidate\n",
    "            if candidate_eval < best_eval:\n",
    "                ticker = 0\n",
    "                best_t, best_eval = np.copy(candidate_t), np.copy(candidate_eval)\n",
    "                best_log = run_markov(best_t)\n",
    "\n",
    "            else:\n",
    "                ticker += 1\n",
    "\n",
    "            # Calculate temperature and Metropolis acceptance criterion\n",
    "            t = starting_temp / (1 + np.log(i + 1))\n",
    "            diff = candidate_eval - curr_eval\n",
    "            metropolis = np.exp(-diff / t)\n",
    "\n",
    "            if diff < 0 or np.random.random() < metropolis:\n",
    "                curr_t, curr_eval = np.copy(candidate_t), candidate_eval\n",
    "\n",
    "            # Print progress report\n",
    "            if verbose and i > 0 and i % print_interval == 0:\n",
    "                progress_report(i, best_eval, best_log, ticker, best_t)\n",
    "\n",
    "            # Check if we should update \"curr\"\n",
    "            diff = (candidate_eval - curr_eval)  # difference between candidate and current point evaluation\n",
    "            metropolis = np.exp(-diff / t)  # calculate metropolis acceptance criterion\n",
    "            if (diff < 0 or np.random.random() < metropolis):  # check if we should keep the new point\n",
    "                curr_t, curr_eval = np.copy(candidate_t), np.copy(candidate_eval)  # store the new current point\n",
    "                ticker = 0\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(best_eval)\n",
    "    \n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sa(tmat=None, save_all=False, n_iterations=50000, step_size=0.2, n_adj=5, obj=\"\"):\n",
    "    \n",
    "    start_tmat = None\n",
    "    start_tmat = tmat if tmat is not None else create_matrix()   \n",
    "    initial_score = gof.objective(run_markov(start_tmat), -1, obj)\n",
    "    print(f\"Initial score: {round(initial_score, 5)}\")\n",
    "    print(\"Starting calibration...\")\n",
    "    \n",
    "    result = simulated_annealing(n_iterations=n_iterations, step_size=step_size, start_tmat=tmat, n_adj=n_adj, verbose=True, obj=obj)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    \n",
    "    curr_tmat = result.copy()\n",
    "    curr_log = run_markov(curr_tmat)\n",
    "\n",
    "    # Extract transition probabilities\n",
    "    transition_probs = p.extract_transition_probs(curr_tmat, c.health_states, c.desired_transitions)\n",
    "\n",
    "    # Saving\n",
    "    if save_all:\n",
    "        # Save the with the timestamp in the filenames\n",
    "        tmat_path, plot_path, probs_path = c.OUTPUT_PATHS[\"tmats\"], c.OUTPUT_PATHS[\"plots\"], c.OUTPUT_PATHS[\"probs\"]\n",
    "        np.save(f\"{tmat_path}/{timestamp}_tmat.npy\", curr_tmat)\n",
    "\n",
    "        p.print_trans_probs(transition_probs, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.print_trans_probs(transition_probs)\n",
    "        p.plot_tps(curr_tmat, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.plot_vs_seer(curr_log, c.seer_inc, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        p.plot_vs_seer_total(curr_log, c.seer_inc, save_imgs=True, outpath=plot_path, timestamp=timestamp)\n",
    "        \n",
    "        out = np.zeros((len(c.points), 80))\n",
    "        for idx, (from_state, to_state) in enumerate(c.points):\n",
    "            out[idx] = curr_tmat[:, from_state, to_state]\n",
    "\n",
    "        pd.DataFrame(out).to_csv(f\"{probs_path}/{timestamp}_tps.csv\")\n",
    "\n",
    "    else:\n",
    "        p.print_trans_probs(transition_probs)\n",
    "        # p.plot_tps(curr_tmat)\n",
    "        # p.plot_vs_seer(curr_log, c.seer_inc)\n",
    "        # p.plot_vs_seer_total(curr_log, c.seer_inc)\n",
    "\n",
    "    return curr_tmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/2/2025 10am: Using our US 1243 model, calibrate to DR incidence and HGPS stage distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR, HGPS:: incidence 1 | polyp 2\n",
      "EPOCH 0/2 -----------------------------------------------------------------------------\n",
      "Initial score: 149649.88833\n",
      "Starting calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:   0%|          | 0/50000 [00:00<?, ?iteration/s]C:\\Users\\sophi\\AppData\\Local\\Temp\\ipykernel_5712\\1051847008.py:45: RuntimeWarning: overflow encountered in exp\n",
      "  metropolis = np.exp(-diff / t)\n",
      "Simulated annealing progress:   0%|          | 6/50000 [00:00<14:18, 58.20iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:171.0, (0.0%)\n",
      "Polyp contribution:151010.0, (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:   5%|▌         | 2510/50000 [00:45<19:42, 40.16iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500: Best Eval: 17084.11552, CRC: 0.01573, Tick: 769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  10%|█         | 5008/50000 [01:28<11:47, 63.58iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:15142.0, (93.0%)\n",
      "Polyp contribution:1186.0, (7.0%)\n",
      "5000: Best Eval: 15730.46932, CRC: 0.01577, Tick: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  15%|█▌        | 7509/50000 [02:10<15:45, 44.93iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500: Best Eval: 14985.17936, CRC: 0.01585, Tick: 1529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  20%|██        | 10008/50000 [02:53<14:42, 45.34iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:14685.0, (81.0%)\n",
      "Polyp contribution:3403.0, (19.0%)\n",
      "10000: Best Eval: 14799.96588, CRC: 0.01629, Tick: 641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  25%|██▌       | 12512/50000 [03:36<08:02, 77.67iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500: Best Eval: 14031.19924, CRC: 0.01587, Tick: 1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  30%|███       | 15011/50000 [04:18<07:36, 76.61iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:14502.0, (94.0%)\n",
      "Polyp contribution:878.0, (6.0%)\n",
      "15000: Best Eval: 14025.87483, CRC: 0.01563, Tick: 1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  35%|███▌      | 17514/50000 [05:01<06:44, 80.21iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500: Best Eval: 14025.87483, CRC: 0.01563, Tick: 4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  40%|████      | 20006/50000 [05:44<12:29, 40.00iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:15240.0, (94.0%)\n",
      "Polyp contribution:1048.0, (6.0%)\n",
      "20000: Best Eval: 13995.48419, CRC: 0.01586, Tick: 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  45%|████▌     | 22515/50000 [06:25<06:06, 75.05iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500: Best Eval: 13709.94912, CRC: 0.01634, Tick: 860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  50%|█████     | 25015/50000 [07:07<05:25, 76.74iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:14536.0, (89.0%)\n",
      "Polyp contribution:1718.0, (11.0%)\n",
      "25000: Best Eval: 13709.94912, CRC: 0.01634, Tick: 3360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  55%|█████▌    | 27504/50000 [07:47<06:30, 57.56iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27500: Best Eval: 13709.94912, CRC: 0.01634, Tick: 5860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  60%|██████    | 30014/50000 [08:31<04:09, 80.01iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:14553.0, (91.0%)\n",
      "Polyp contribution:1505.0, (9.0%)\n",
      "30000: Best Eval: 13709.94912, CRC: 0.01634, Tick: 8360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  65%|██████▌   | 32514/50000 [09:17<03:43, 78.37iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32500: Best Eval: 13709.94912, CRC: 0.01634, Tick: 10860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  70%|███████   | 35011/50000 [10:00<03:05, 80.75iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:15919.0, (96.0%)\n",
      "Polyp contribution:655.0, (4.0%)\n",
      "35000: Best Eval: 13476.33552, CRC: 0.01635, Tick: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  75%|███████▌  | 37507/50000 [10:43<04:02, 51.54iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37500: Best Eval: 13476.33552, CRC: 0.01635, Tick: 2980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  80%|████████  | 40003/50000 [12:05<04:52, 34.12iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:15053.0, (97.0%)\n",
      "Polyp contribution:502.0, (3.0%)\n",
      "40000: Best Eval: 13476.33552, CRC: 0.01635, Tick: 5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  85%|████████▌ | 42503/50000 [14:02<08:45, 14.28iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42500: Best Eval: 13476.33552, CRC: 0.01635, Tick: 7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  90%|█████████ | 45009/50000 [16:00<01:18, 63.84iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEER contribution:15350.0, (97.0%)\n",
      "Polyp contribution:516.0, (3.0%)\n",
      "45000: Best Eval: 13476.33552, CRC: 0.01635, Tick: 10480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress:  95%|█████████▌| 47516/50000 [16:41<00:30, 80.46iteration/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47500: Best Eval: 13476.33552, CRC: 0.01635, Tick: 12980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulated annealing progress: 100%|██████████| 50000/50000 [17:21<00:00, 48.00iteration/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13476.33552277643\n",
      "Monthly transition probabilities\n",
      "healthy to LR_polyp: Min: 0.00000, Max: 0.00039, Average: 0.00023\n",
      "LR_polyp to HR_polyp: Min: 0.00038, Max: 0.00116, Average: 0.00088\n",
      "HR_polyp to u_CRC_loc: Min: 0.00038, Max: 0.00417, Average: 0.00168\n",
      "u_CRC_loc to u_CRC_reg: Min: 0.00309, Max: 0.12876, Average: 0.06274\n",
      "u_CRC_reg to u_CRC_dis: Min: 0.07917, Max: 0.12876, Average: 0.09930\n",
      "u_CRC_loc to d_CRC_loc: Min: 0.00000, Max: 0.00974, Average: 0.00469\n",
      "u_CRC_reg to d_CRC_reg: Min: 0.03388, Max: 0.15985, Average: 0.10628\n",
      "u_CRC_dis to d_CRC_dis: Min: 0.21147, Max: 0.49143, Average: 0.40838\n",
      "\n",
      "Annual transition probabilities\n",
      "healthy to LR_polyp: Min: 0.00001, Max: 0.00462, Average: 0.00280\n",
      "LR_polyp to HR_polyp: Min: 0.00455, Max: 0.01384, Average: 0.01046\n",
      "HR_polyp to u_CRC_loc: Min: 0.00455, Max: 0.04892, Average: 0.01993\n",
      "u_CRC_loc to u_CRC_reg: Min: 0.03647, Max: 0.80873, Average: 0.46960\n",
      "u_CRC_reg to u_CRC_dis: Min: 0.62835, Max: 0.80873, Average: 0.71049\n",
      "u_CRC_loc to d_CRC_loc: Min: 0.00001, Max: 0.11085, Average: 0.05413\n",
      "u_CRC_reg to d_CRC_reg: Min: 0.33870, Max: 0.87632, Average: 0.70443\n",
      "u_CRC_dis to d_CRC_dis: Min: 0.94222, Max: 0.99970, Average: 0.99256\n"
     ]
    }
   ],
   "source": [
    "result=np.load(\"../out/DR/HGPS_I1_P1/tmats/20240924_2148_tmat.npy\")\n",
    "print(f\"{c.model_version}, {c.stage}:: incidence {c.inc_factor} | polyp {c.polyp_factor}\")\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"EPOCH {epoch+1}/5 -----------------------------------------------------------------------------\")\n",
    "    for batch in range(100):\n",
    "        print(f\"BATCH {batch+1}/100 ----------------------------------------------\")\n",
    "        save = True if batch==99 else False\n",
    "        result = run_sa(result, False, n_iterations=100, step_size = 0.25, n_adj=5, obj=\"pol\")\n",
    "        result = run_sa(result, save, n_iterations=1000, step_size = 0.25, n_adj=5)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load(\"../out/DR/HGPS_I1_P1/tmats/20240924_2148.npy\")  # Start: DR HGPS tmat\n",
    "out = np.zeros((len(c.points), 80))\n",
    "for idx, (from_state, to_state) in enumerate(c.points):\n",
    "    out[idx] = t[:, from_state, to_state]\n",
    "\n",
    "#pd.DataFrame(out).to_csv(f\"{probs_path}/{timestamp}_tps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(out).to_csv(f\"{c.OUTPUT_PATHS[\"probs\"]}/20250102_1233_tps.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective_cp(tmat):\n",
    "    score = 0\n",
    "    cp = cancer_progression(tmat)\n",
    "    score += np.square(cp-3.0).sum()\n",
    "    return score\n",
    "    \n",
    "def cancer_progression(tmat):\n",
    "    \"\"\"\n",
    "    Calculate time from preclinical local to preclinical distant. MFPT\n",
    "    \"\"\"\n",
    "    p_12 = tmat[:, 3, 4] # loc to reg\n",
    "    p_23 = tmat[:, 4, 5] # reg to dis\n",
    "    p_11 = tmat[:, 3, 3] # stay loc\n",
    "    p_22 = tmat[:, 4, 4] # stay reg\n",
    "    p_33 = tmat[:, 5, 5] # stay dis\n",
    "    \n",
    "    cp = (1 + p_12 * (1 + p_23 * (1 / (1 - p_33))) * (1 / (1 - p_22))) * (1 / (1 - p_11))\n",
    "    \n",
    "    return cp\n",
    "    \n",
    "    \n",
    "def sojourn_time_weighted(tm, metric=\"mean\"):\n",
    "    \"\"\"\n",
    "    Calculate  time spent in each path.\n",
    "    \"\"\"\n",
    "    in_loc, in_reg, in_dis = [1/(1-tm[:, x, x]) for x in [3,4,5]]\n",
    "    mloc = in_loc\n",
    "    mreg = in_loc + in_reg\n",
    "    mdis = (in_loc + in_reg * tm[:, 3, 4]) + in_dis\n",
    "    \n",
    "    if metric == \"mean\": # Mean across paths per age\n",
    "        sj_time =  np.mean([mloc, mreg, mdis], axis=0)\n",
    "    else: # Each path per age\n",
    "        sj_time = np.array([mloc, mreg, mdis])\n",
    "    \n",
    "    return sj_time\n",
    "\n",
    "def sojourn_time_weighted2(tm):\n",
    "    \"\"\"\n",
    "    Calculate  time spent in each path, weighted by stage.\n",
    "    \"\"\"\n",
    "    in_loc, in_reg, in_dis = [1/(1-tm[:, x, x]) for x in [3,4,5]]\n",
    "    mloc = in_loc\n",
    "    mreg = in_loc * tm[:, 3, 4] + in_reg\n",
    "    mdis = in_loc * tm[:, 3, 4] + in_reg * tm[:, 4, 5] + in_dis\n",
    "    sj_time = np.array([mloc, mreg, mdis])\n",
    "    \n",
    "    return sj_time\n",
    "\n",
    "def sojourn_time_in_stage(tmat):\n",
    "    \"\"\"\n",
    "    Calculate mean time in each state. Average over all states.\n",
    "    \"\"\"\n",
    "    sojourn_times = np.zeros((3,80))\n",
    "    for i in np.arange(3,6,1):\n",
    "        p_stay = tmat[:, i, i]\n",
    "        sojourn_times[i-3] = 1 / (1 - p_stay)\n",
    "    return sojourn_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmat = np.load(\"../out/US/interp/tmats/20240923_1243_tmat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem, t\n",
    "\n",
    "def summarize_data(data):\n",
    "    \"\"\"\n",
    "    Returns the min, max, median, mean, and 95% confidence interval of a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list or numpy array): Input data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary statistics\n",
    "    \"\"\"\n",
    "    if len(data) == 0:\n",
    "        return \"Data is empty.\"\n",
    "    \n",
    "    # Convert to numpy array for convenience\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Summary statistics\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    median_val = np.median(data)\n",
    "    mean_val = np.mean(data)\n",
    "    \n",
    "    # Compute 95% confidence interval\n",
    "    confidence = 0.95\n",
    "    n = len(data)\n",
    "    if n > 1:\n",
    "        std_err = sem(data)\n",
    "        h = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "        ci_lower = mean_val - h\n",
    "        ci_upper = mean_val + h\n",
    "    else:\n",
    "        ci_lower = ci_upper = mean_val  # No confidence interval for a single data point\n",
    "\n",
    "    return {\n",
    "        \"min\": min_val,\n",
    "        \"max\": max_val,\n",
    "        \"median\": median_val,\n",
    "        \"mean\": mean_val,\n",
    "        \"95% CI\": (ci_lower, ci_upper)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, reg, dis = sojourn_time_weighted(tmat, metric=\"\")\n",
    "total = sojourn_time_weighted(tmat)\n",
    "print(summarize_data(loc))\n",
    "print(summarize_data(reg))\n",
    "print(summarize_data(dis))\n",
    "print(summarize_data(total))\n",
    "\n",
    "plt.plot(np.arange(0,80,1), loc, color=\"blue\", label=\"L\")\n",
    "plt.plot(np.arange(0,80,1), reg, color=\"red\", label=\"R\")\n",
    "plt.plot(np.arange(0,80,1), dis, color=\"green\", label=\"D\")\n",
    "plt.plot(np.arange(0,80,1), total, color=\"grey\", label=\"All\")\n",
    "plt.title(\"Sojourn Time by Age (cumulative uL->dX)\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Months\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "plt.hist(loc, bins=30, density=True, alpha=0.6, color=\"blue\", label=\"Loc\")\n",
    "plt.hist(reg, bins=30, density=True, alpha=0.6, color=\"red\", label=\"Reg\")\n",
    "plt.hist(dis, bins=30, density=True, alpha=0.6, color=\"green\", label=\"Dis \")\n",
    "sns.kdeplot(loc, fill=True, color=\"blue\", alpha=0.3, clip=(0, None))  \n",
    "sns.kdeplot(reg, fill=True, color=\"red\", alpha=0.3, clip=(0, None))  \n",
    "sns.kdeplot(dis, fill=True, color=\"green\", alpha=0.3, clip=(0, None))\n",
    "plt.title(\"Density Distribution of Sojourn Time by Stage at DX (cumulative uL->dX)\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, reg, dis = sojourn_time_weighted2(tmat)\n",
    "print(summarize_data(loc))\n",
    "print(summarize_data(reg))\n",
    "print(summarize_data(dis))\n",
    "plt.plot(np.arange(0,80,1), loc, color=\"blue\", label=\"L\")\n",
    "plt.plot(np.arange(0,80,1), reg, color=\"red\", label=\"R\")\n",
    "plt.plot(np.arange(0,80,1), dis, color=\"green\", label=\"D\")\n",
    "plt.title(\"Sojourn Time by Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Months\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(loc, bins=30, density=True, alpha=0.6, color=\"blue\")\n",
    "plt.hist(reg, bins=30, density=True, alpha=0.6, color=\"red\")\n",
    "plt.hist(dis, bins=30, density=True, alpha=0.6, color=\"green\")\n",
    "sns.kdeplot(loc, fill=True, color=\"blue\", alpha=0.3, clip=(0, None), label=\"loc\")  \n",
    "sns.kdeplot(reg, fill=True, color=\"red\", alpha=0.3, clip=(0, None), label=\"reg\")  \n",
    "sns.kdeplot(dis, fill=True, color=\"green\", alpha=0.3, clip=(0, None), label=\"dis\")  \n",
    "plt.title(\"Density Distribution of Sojourn Time\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_data(cancer_progression(tmat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_conditional_probs(matrix):\n",
    "    \"\"\"\n",
    "    Converts a transition matrix into conditional probabilities for TreeAge.\n",
    "    \n",
    "    Parameters:\n",
    "        matrix (numpy.ndarray): Transition matrix of shape (n_ages, n_states, n_states).\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Conditional transition matrix of the same shape.\n",
    "    \"\"\"\n",
    "    conditional_matrix = np.copy(matrix)\n",
    "\n",
    "    # Loop through all transitions to adjust probabilities\n",
    "    for (from_idx, to_idx), (from_state, to_state) in zip(c.points, c.desired_transitions): \n",
    "        # Compute survival probability (1 - ACM)\n",
    "        p_survive = 1 - matrix[:, from_idx, c.acm_states[from_idx]].clip(1e-10, 1.0)\n",
    "\n",
    "        # Normalize by survival probability\n",
    "        conditional_matrix[:, from_idx, to_idx] /= p_survive\n",
    "\n",
    "        # If transition is progression (e.g., u_PDAC_x -> u_PDAC_x+1), normalize by p(no_dx)\n",
    "        if from_idx in [3,4,5] and to_idx == from_idx + 1:  # Progression\n",
    "            dx_state = from_idx + 3  # Corresponding diagnosed state\n",
    "            p_no_dx = 1 - matrix[:, from_idx, dx_state].clip(1e-10, 1.0)\n",
    "            conditional_matrix[:, from_idx, to_idx] /= p_no_dx \n",
    "    return conditional_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmat = np.load(\"../out/US/interp/tmats/20240923_1243_tmat.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmat_c = convert_to_conditional_probs(tmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transition_probs(tmat, type=\"markov\", metric=\"all\"):\n",
    "    \"\"\"\n",
    "    Extracts and optionally saves transition probabilities from a transition matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        tmat (numpy.ndarray): Transition probability matrix of shape (n_ages, n_states, n_states).\n",
    "        type (str): Type of model (\"markov\" or other). Determines age range.\n",
    "        save (bool): Whether to save the output as a CSV file.\n",
    "        outpath (str): Path to save the CSV file. Required if save=True.\n",
    "        timestamp (str): Custom timestamp for the filename. Defaults to current datetime.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Transition probabilities dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    tmat = convert_to_conditional_probs(tmat) if type == \"treeage\" else tmat\n",
    "    age_range = np.arange(20,100,1)\n",
    "    data = []\n",
    "    df = None \n",
    "    \n",
    "    if metric == \"all\":\n",
    "        for (from_idx, to_idx), (from_state, to_state) in zip(c.points, c.desired_transitions):\n",
    "            for age, probs in zip(age_range, tmat[:, from_idx, to_idx]):\n",
    "                data.append({\n",
    "                    \"Age\": age,\n",
    "                    \"From State\": from_state,\n",
    "                    \"To State\": to_state,\n",
    "                    \"Probability\": probs\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    elif metric == \"avg\":\n",
    "        for (from_idx, to_idx), (from_state, to_state) in c.transitions_itos.items():\n",
    "            probs = [round(p,5) for p in tmat[:, from_idx, to_idx]]\n",
    "            data.append({\n",
    "                \"From State\": from_state,\n",
    "                \"To State\": to_state,\n",
    "                \"Age 30\": probs[10],\n",
    "                \"Age 75\": probs[-10],\n",
    "                 \"Min\": min(probs),\n",
    "                 \"Max\": max(probs),\n",
    "                 \"Avg\": round(np.mean(probs),5)\n",
    "            })\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    else:\n",
    "        print(\"Wrong metric specified in extract_transition_probs. Need [avg, all]\")\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_transition_probs(tmat_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../out/US/interp/probs/20240923_1243_c.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drcrc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
